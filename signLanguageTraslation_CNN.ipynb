{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '2020동계방학계획표.hwp', 'signLanguageTraslation_CNN.ipynb', 'sign_mnist_test.csv', 'sign_mnist_train.csv', '방학일일계획표.hwp']\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3257261418dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "print(os.listdir())\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Exploratory Analysis of Training Data\n",
    "data = pd.read_csv('sign-language-mnist/sign_mnist_train.csv')\n",
    "print('Dataframe Shape:', data.shape)\n",
    "\n",
    "data.head()\n",
    "\n",
    "x = data.iloc[:, 1:].values\n",
    "print(\"Number of images:\", x.shape[0])\n",
    "print(\"Number of pixels in each image:\", x.shape[1])\n",
    "\n",
    "y = data.iloc[:, :1].values.flatten()\n",
    "print('Labels:\\n', y)\n",
    "print('Shape of Labels:', y.shape)\n",
    "\n",
    "def next_batch(batch_size, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[: batch_size]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "def display_images(data):\n",
    "    x, y = data\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(x[i].reshape(28, 28), cmap = 'binary')\n",
    "        ax.set_xlabel(chr(y[i] + 65))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "display_images(next_batch(9, x, y))\n",
    "\n",
    "z = dict(Counter(list(y)))\n",
    "labels = z.keys()\n",
    "frequencies = [z[i] for i in labels]\n",
    "labels = [chr(i + 65) for i in z.keys()]\n",
    "\n",
    "plt.figure(figsize = (20, 10))\n",
    "plt.bar(labels, frequencies)\n",
    "plt.title('Frequency Distribution of Alphabets', fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "def one_hot_encode(y):\n",
    "    return np.eye(25)[y]\n",
    "y_encoded = one_hot_encode(y)\n",
    "print('Shape of y after encoding:', y_encoded.shape)\n",
    "\n",
    "# building the convolutional Neural Network\n",
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 2000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Neural Network Hyperparameters\n",
    "n_input = 784\n",
    "n_classes = 25\n",
    "dropout = 0.75\n",
    "\n",
    "# Placeholders\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_input]) # Placeholder for Feature Matrix\n",
    "Y = tf.placeholder(tf.float32, shape = [None, n_classes]) # Placeholder for Labels\n",
    "keep_prob = tf.placeholder(tf.float32) # Placeholder for Dropout Rate\n",
    "\n",
    "weights = {\n",
    "    # Weight for Convolutional Layer 1: 5x5 filter, 1 input channel, 32 output channels\n",
    "    'w1' : tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # Weight for Convolutional Layer 2: 5x5 filter, 32 input channels, 64 output channels\n",
    "    'w2' : tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # Weight for Fully Connected Layer 1: 49 * 64 input channels, 1024 output channels\n",
    "    'w3' : tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "    # Weight for Convolutional Layer 1: 1024 input channels, 25(number of classes) output channels\n",
    "    'w4' : tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    # Bias for Convolutional Layer 1\n",
    "    'b1' : tf.Variable(tf.random_normal([32])),\n",
    "    # Bias for Convolutional Layer 2\n",
    "    'b2' : tf.Variable(tf.random_normal([64])),\n",
    "    # Bias for Fully Connected Layer 1\n",
    "    'b3' : tf.Variable(tf.random_normal([1024])),\n",
    "    # Bias for Outout Layer\n",
    "    'b4' : tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Wrapper function for creating a Convolutional Layer\n",
    "def conv2d(x, W, b, strides = 1):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# Wrapper function for creating a Pooling Layer\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'SAME')\n",
    "\n",
    "def neural_network(x, weight, bias, dropout):\n",
    "    x = tf.reshape(x, shape = [-1, 28, 28, 1])\n",
    "    \n",
    "    conv1 = conv2d(x, weight['w1'], bias['b1']) # Convolutional Layer 1\n",
    "    conv1 = maxpool2d(conv1) # Pooling Layer 1\n",
    "    \n",
    "    conv2 = conv2d(conv1, weight['w2'], bias['b2']) # Convolutional Layer 1\n",
    "    conv2 = maxpool2d(conv2) # Pooling Layer 1\n",
    "    \n",
    "    # Fully Connected Layer 1\n",
    "    # Reshaping output of previous convolutional layer to fit the fully connected layer\n",
    "    fc = tf.reshape(conv2, [-1, weights['w3'].get_shape().as_list()[0]])\n",
    "    fc = tf.add(tf.matmul(fc, weight['w3']), bias['b3']) # Linear Function\n",
    "    fc = tf.nn.relu(fc) # Activation Function\n",
    "    \n",
    "    fc = tf.nn.dropout(fc, dropout) # Applying dropout on Fully Connected Layer\n",
    "    \n",
    "    out = tf.add(tf.matmul(fc, weight['w4']), bias['b4']) # Output Layer\n",
    "    return out\n",
    "\n",
    "logits = neural_network(X, weights, biases, keep_prob)\n",
    "loss_op = tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = Y)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Training the Neural Network\n",
    "# Splitting the dataset into Training and Holdout(Test set)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y_encoded, test_size = 0.33, random_state = 42)\n",
    "print('X train shape', X_train.shape)\n",
    "print('y train shape', y_train.shape)\n",
    "print('X test shape', X_test.shape)\n",
    "print('y test shape', y_test.shape)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Running Initializer\n",
    "    sess.run(init)\n",
    "    cost_hist, acc_hist = [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        _x, _y = next_batch(batch_size, X_train, y_train)\n",
    "        # Running Optimizer\n",
    "        sess.run(train_op, feed_dict = { X : _x, Y : _y, keep_prob : dropout })\n",
    "        if epoch % display_step == 0:\n",
    "            # Calculating Loss and Accuracy on the current Epoch\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict = { X : _x, Y : _y, keep_prob : 1.0 })\n",
    "            loss = sum(loss)\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n",
    "    print('-' * 50)\n",
    "    print('\\nOptimization Finished\\n')\n",
    "    print('Accuracy on Training Data: ' + str(sess.run(accuracy,\n",
    "                                                       feed_dict = {\n",
    "                                                           X : X_train,\n",
    "                                                           Y : y_train,\n",
    "                                                           keep_prob : 1.0\n",
    "                                                       }) * 100) + ' %')\n",
    "    print('Accuracy on Test Data: ' + str(sess.run(accuracy,\n",
    "                                                   feed_dict = {\n",
    "                                                       X : X_test,\n",
    "                                                       Y : y_test,\n",
    "                                                       keep_prob : 1.0\n",
    "                                                   }) * 100) + ' %')\n",
    "    \n",
    "plt.plot(list(range(len(cost_hist))), cost_hist)\n",
    "plt.title(\"Change in cost\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(acc_hist))), acc_hist)\n",
    "plt.title(\"Change in accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# Training the Neural Network on the whole dataset to get the Optimized Weights and Biases\n",
    "print('Training on the whole dataset....\\n')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # Running Initializer\n",
    "    cost_hist, acc_hist = [], []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        _x, _y = next_batch(batch_size, x, y_encoded)\n",
    "        # Running Optimizer\n",
    "        sess.run(train_op,\n",
    "                 feed_dict = {\n",
    "                     X : _x,\n",
    "                     Y : _y,\n",
    "                     keep_prob : dropout\n",
    "                 })\n",
    "        if epoch % display_step == 0:\n",
    "            # Calculating Loss and Accuracy on the current Epoch\n",
    "            loss, acc = sess.run([loss_op, accuracy],\n",
    "                                 feed_dict = {\n",
    "                                     X : _x,\n",
    "                                     Y : _y,\n",
    "                                     keep_prob : 1.0\n",
    "                                 })\n",
    "            loss = sum(loss)\n",
    "            cost_hist.append(loss)\n",
    "            acc_hist.append(acc)\n",
    "            print('Epoch ' + str(epoch) + ', Cost: ' + str(loss) + ', Accuracy: ' + str(acc * 100) + ' %')\n",
    "    print('-' * 50)\n",
    "    print('\\nOptimization Finished\\n')\n",
    "    print('Accuracy after training on whole dataset Data: ' + str(sess.run(accuracy,\n",
    "                                                       feed_dict = {\n",
    "                                                           X : x,\n",
    "                                                           Y : y_encoded,\n",
    "                                                           keep_prob : 1.0\n",
    "                                                       }) * 100) + ' %')\n",
    "    W = sess.run(weights)\n",
    "    B = sess.run(biases)\n",
    "    \n",
    "plt.plot(list(range(len(cost_hist))), cost_hist)\n",
    "plt.title(\"Change in cost\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(list(range(len(acc_hist))), acc_hist)\n",
    "plt.title(\"Change in accuracy\")\n",
    "plt.show()\n",
    "\n",
    "data_test = pd.read_csv('../input/sign_mnist_test.csv')\n",
    "print('Dataframe Shape:', data_test.shape)\n",
    "\n",
    "data_test.head()\n",
    "\n",
    "x_test = data_test.iloc[:, 1:].values\n",
    "y_test = data_test.iloc[:, :1].values.flatten()\n",
    "y_test = one_hot_encode(y_test)\n",
    "x_test.shape, y_test.shape\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, n_input]) # Placeholder for Feature Matrix\n",
    "Y = tf.placeholder(tf.float32, shape = [None, n_classes]) # Placeholder for Labels\n",
    "keep_prob = tf.placeholder(tf.float32) # Placeholder for Dropout Rate\n",
    "\n",
    "y_pred = neural_network(X, W, B, 1.0)\n",
    "\n",
    "def get_prediction(img):\n",
    "    with tf.Session() as sess:\n",
    "        pred = sess.run(y_pred, feed_dict = { X : img, keep_prob : 1.0 })\n",
    "    img = img.reshape(28, 28)\n",
    "    pred = list(pred.flatten())\n",
    "    pred = chr(pred.index(max(pred)) + 65)\n",
    "    return (img, pred)\n",
    "\n",
    "image, pred = get_prediction(x_test[1].reshape(1, 784))\n",
    "plt.imshow(image, cmap = 'binary')\n",
    "plt.title(pred)\n",
    "plt.show()\n",
    "\n",
    "# Saving Parameters\n",
    "for key in W.keys():\n",
    "    np.save(key, W[key])\n",
    "\n",
    "for key in B.keys():\n",
    "    np.save(key, B[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
